{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     \n",
    "import numpy as np \n",
    "import glob as glob\n",
    "\n",
    "Base=[]\n",
    "csv_files = glob.glob('Data_EAM&IPC/*.csv')\n",
    "\n",
    "for filename in csv_files:\n",
    "    if filename == \"Data_EAM&IPC\\\\EAM_2020.csv\":\n",
    "        print(\"ok\")\n",
    "        data = pd.read_csv(filename,sep=\",\")   \n",
    "    else:\n",
    "        data = pd.read_csv(filename,sep=\";\")\n",
    "      \n",
    "    Base.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EAM08,EAM09,EAM10,EAM11,EAM12,EAM13,EAM14,EAM15,EAM16,EAM17,EAM18,EAM19,EAM20 = Base\n",
    "#Assign each dataframe a variable of the \"Base\"\n",
    "Data_Merge = [EAM08,EAM09,EAM10,EAM11,EAM12,EAM13,EAM14,EAM15,EAM16,EAM17,EAM18,EAM19,EAM20]\n",
    "#Create a list of the dataframe\n",
    "EAM08_G,EAM09_G,EAM10_G,EAM11_G,EAM12_G,EAM13_G,EAM14_G, \\\n",
    "            EAM15_G,EAM16_G,EAM17_G,EAM18_G,EAM19_G,EAM20_G=\\\n",
    "                0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "Data_Gruop = [EAM08_G,EAM09_G,EAM10_G,EAM11_G,EAM12_G,EAM13_G,EAM14_G, \\\n",
    "            EAM15_G,EAM16_G,EAM17_G,EAM18_G,EAM19_G,EAM20_G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARA CAMBIAR UN LABEL EN UNA UBICACIÓN ESPECIFICA NO ESTANDARIZADO\n",
    "def change_name(Data_Merge, Number, change):\n",
    "    for df in Data_Merge:\n",
    "        if len(df.columns) > Number: #Verificar si el dataframe tiene al menos 4 columnas\n",
    "            df.columns.values[Number] = change #Me cambia el name de el label \n",
    "    return Data_Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para estandairzar los labels\n",
    "def change_label(Data_Merge):\n",
    "    for df in Data_Merge:\n",
    "        columnas = df.columns.tolist() #Crea una lista de columnas\n",
    "        nuevas_columnas = [columna.upper() for columna in columnas] # coloca en mayusculas cada columna de lista\n",
    "        df.columns = nuevas_columnas #Asigna el nuevo nombre\n",
    "    return Data_Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para saber si una columna esta presente en un dataframe\n",
    "def Exis(Data_Merge, item):\n",
    "    for i, df in enumerate(Data_Merge):\n",
    "        if item not in df.columns:\n",
    "            columna_ausente = True\n",
    "            print(f\"El item no está presente en el DataFrame {i}.\")\n",
    "        else:\n",
    "            columna_ausente = False\n",
    "            print(f\"El item  está presente en el DataFrame {i}.\")\n",
    "    return columna_ausente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para saber si existen datos faltantes en la columna\n",
    "def exis_colum(Data_Merge,colum):\n",
    "    missing_col=0\n",
    "    for i in Data_Merge:\n",
    "        missing_col += i[colum].isnull().sum()\n",
    "    return missing_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para ordenar, por una columna \n",
    "def Sort(Column,Data_Merge):\n",
    "    for i, d in enumerate(Data_Merge):\n",
    "        sorted_df = d.sort_values(by=Column)\n",
    "        Data_Merge[i] = sorted_df \n",
    "    return Data_Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_or_sum(Column, SUMATION, UBACATION, Data_Gruop, Data_Merge, operation):\n",
    "    for i, df in enumerate(Data_Gruop):\n",
    "        for index in df.index:\n",
    "            if index in Data_Merge[i][Column].unique():\n",
    "                total = Data_Merge[i][Data_Merge[i][Column] == index][SUMATION]\n",
    "                if operation == 'mean':\n",
    "                    total=total.mean()\n",
    "                    df.loc[index, UBACATION] = total\n",
    "                elif operation == 'sum':\n",
    "                    total=total.sum()\n",
    "                    df.loc[index, UBACATION] = total\n",
    "                elif operation == 'count':\n",
    "                    total=total.value_counts()           \n",
    "                    df.loc[index, UBACATION] = int(total)           \n",
    "                elif operation == 'coe_sim':\n",
    "                    total=total.skew()  #Da como resultado el coeficiente de asimetria de fisher\n",
    "                    df.loc[index, UBACATION] = total\n",
    "                elif operation == \"med\":\n",
    "                    total=total.median()\n",
    "                    df.loc[index, UBACATION] = total\n",
    "                elif operation ==\"rango\":\n",
    "                    total = total.max() - total.min()\n",
    "                    df.loc[index, UBACATION] = total\n",
    "    return Data_Gruop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_rows(row,Colum1,Colum2):\n",
    "    return row[Colum1] + row[Colum2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_of_rows(row,Colum1,Colum2):\n",
    "    return row[Colum1] * row[Colum2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IHH(Column, Divisor, Numerator, Ubac, Data_Gruop, Data_Merge):\n",
    "  for i, df in enumerate(Data_Gruop):\n",
    "    for index in df.index:\n",
    "      if index in Data_Merge[i][Column].unique():               \n",
    "        Numerator = Data_Merge[i].set_index(Column)[Divisor]\n",
    "        Denominator = df[\"SUM-WORKERS\"]\n",
    "        Total = (Numerator / Denominator) * 100\n",
    "        Data_Merge[i].loc[Data_Merge[i][Column], Ubac] = Total\n",
    "  return Data_Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Merge = change_name(Data_Merge,3,\"CIIU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Merge = change_label(Data_Merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exis_colum(Data_Merge,\"CIIU\")\n",
    "exis_colum(Data_Merge,\"C4R4C9T\")\n",
    "exis_colum(Data_Merge,\"C4R4C10T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Merge=Sort(\"CIIU\",Data_Merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para crear un data frame agrupado de una base de datos\n",
    "for i in range (len(Data_Merge)):\n",
    "    index=Data_Merge[i][\"CIIU\"].drop_duplicates().sort_values()\n",
    "    Data_Gruop[i]= pd.DataFrame(index=index,columns=[\"SUM-WORKERS_M\",\"SUM-WORKERS_F\",\"SUM-WORKERS\",\"MED-WAGE\",\"IHH\",\"Count_CIIU\",'Simetria',\"rango\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Gruop=calculate_avg_or_sum(\"CIIU\",\"C4R4C9T\",\"SUM-WORKERS_F\",Data_Gruop,Data_Merge,\"sum\")\n",
    "Data_Gruop=calculate_avg_or_sum(\"CIIU\",\"C4R4C10T\",\"SUM-WORKERS_M\",Data_Gruop,Data_Merge,\"sum\")\n",
    "Data_Gruop=calculate_avg_or_sum(\"CIIU\",\"C3R2C3\",\"MED-WAGE\",Data_Gruop,Data_Merge,\"med\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df  in Data_Gruop:\n",
    "    df[\"SUM-WORKERS\"] = df.apply(lambda row: sum_of_rows(row,\"SUM-WORKERS_M\",\"SUM-WORKERS_F\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df  in Data_Merge:\n",
    "    df[\"WORKERS\"] = df.apply(lambda row: sum_of_rows(row,\"C4R4C10T\",\"C4R4C9T\"), axis=1) #Sumar las filas\n",
    "    df[\"IHH_ONE\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Merge=IHH(\"CIIU\",\"WORKERS\",\"SUM-WORKERS\",\"IHH_ONE\",Data_Gruop,Data_Merge) #Aquí estoy sacando el ihh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Gruop=calculate_avg_or_sum(\"CIIU\",\"IHH_ONE\",\"IHH\",Data_Gruop,Data_Merge,\"sum\") ##Sumo el IHH individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Gruop=calculate_avg_or_sum(\"CIIU\",\"CIIU\",\"Count_CIIU\",Data_Gruop,Data_Merge,\"count\")   ## Cuanto la cantidad de empresas que hay ´por CIIU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Gruop=calculate_avg_or_sum(\"CIIU\",\"C3R2C3\",\"Simetria\",Data_Gruop,Data_Merge,\"coe_sim\")  #Miro el coeficiente de simetria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Gruop=calculate_avg_or_sum(\"CIIU\",\"C3R2C3\",\"rango\",Data_Gruop,Data_Merge,\"rango\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(Data_Gruop):\n",
    "    df[\"IHH_cuadrado\"] = df[\"IHH\"] ** 2\n",
    "\n",
    "    conditions = [\n",
    "        df[\"IHH_cuadrado\"] <= 1000,\n",
    "        (1000 <= df[\"IHH_cuadrado\"]) & (df[\"IHH_cuadrado\"] < 1800),\n",
    "        df[\"IHH_cuadrado\"] >= 1800\n",
    "    ]\n",
    "    values = [1, 2, 3]\n",
    "\n",
    "    df[\"IHH_resultado\"] = np.select(conditions, values, default=np.nan)\n",
    "\n",
    "    #Hay un problema y es que son 3 .-."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exis_colum(Data_Gruop,\"IHH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Promedios Ponderados  -- para calcular \n",
    "#Para el salario se saca la mediana pagada por cada sector \n",
    "# Para saber si el promedio es un buen estadistico se realiza un examen de simetria\n",
    "#Datos de estilizados -- Indicador: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comienza a trabajar con los datos sacados por hechos estilizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imprime una grafica de barras del IHH por sector para todos los años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_IHH(Grupo_datos, df,SUM):\n",
    "    for i, data_frame in enumerate(Grupo_datos):\n",
    "        conteo = data_frame[SUM].value_counts()\n",
    "        for valor in conteo.index:\n",
    "            conteo_valor = conteo.loc[valor]\n",
    "            df.at[df.index[i], valor] = conteo_valor\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(Data_Gruop):\n",
    "    Index=[]\n",
    "    for i in range(len(Data_Gruop)):\n",
    "        w = 2008 + i \n",
    "        Index.append(w)\n",
    "    return Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index = create_index(Data_Gruop)\n",
    "Columns = [1, 2, 3]\n",
    "df = pd.DataFrame(index=Index, columns=Columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=count_IHH(Data_Gruop,df,\"IHH_resultado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Crear una figura para el gráfico\n",
    "# plt.figure()\n",
    "\n",
    "# # Graficar los resultados de IHH_resultado con un gráfico de barras\n",
    "# df.plot(kind='bar', width=0.8)\n",
    "\n",
    "# # Etiquetas y título del gráfico\n",
    "# plt.xlabel(\"Años\")\n",
    "# plt.ylabel(\"Cantidad de Sectores\")\n",
    "# plt.title(\"Resultados de IHH por Índice\")\n",
    "\n",
    "\n",
    "# # Mostrar el gráfico\n",
    "# plt.show()\n",
    "#plt.savefig('grafico_Sectores.jpg', format='jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imprime una grafica con la media  del salario medio pagado por sectores con poder y sin poder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prom = create_index(Data_Gruop)\n",
    "X=['Salario_Medio']  # Acá se crea la columna vacia\n",
    "Promedio_years= pd.DataFrame(index=Index, columns=X)\n",
    "\n",
    "#Creamos un dataframe donde agrupa la mediana de cada CIIU para cada año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo de Excel\n",
    "IPC_doc = pd.read_excel(\"Data_EAM&IPC\\\\IPC.xlsx\", header=0)\n",
    "\n",
    "# Crear un DataFrame IPC a partir de los datos leídos\n",
    "IPC = pd.DataFrame({'Año': IPC_doc.iloc[:, 0], 'IPC': IPC_doc.iloc[:, 1]})\n",
    "\n",
    "Index = create_index(Data_Gruop)\n",
    "\n",
    "# Establecer el índice del DataFrame IPC usando la lista Index\n",
    "IPC.set_index('Año', inplace=True)\n",
    "\n",
    "# Reemplazar el índice existente con la lista Index\n",
    "IPC.index = Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=[]\n",
    "for i in Data_Gruop:\n",
    "    X = i['MED-WAGE'].median()\n",
    "    T.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Promedio_years['Salario_Medio'] = T\n",
    "Promedio_years[\"InflaciónIPC\"] = IPC[\"IPC\"]\n",
    "Promedio_years['Salario_Real'] = (Promedio_years[\"Salario_Medio\"]  / Promedio_years[\"InflaciónIPC\"]) *100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Supongamos que 'df' es tu DataFrame con una columna \"Datos\" y un índice deseado en el eje X\n",
    "\n",
    "# # Obtén los valores del índice y los datos de las columnas\n",
    "# x_values = Promedio_years.index\n",
    "# y_values_1 = Promedio_years['Salario_Real']\n",
    "# y_values_2 = Promedio_years['Salario_Medio']\n",
    "\n",
    "# # Crea la figura y los ejes\n",
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# # Crea un segundo eje Y que comparta el mismo eje X\n",
    "# ax2 = ax1.twinx()\n",
    "\n",
    "# # Trazar datos en el primer eje Y\n",
    "# ax1.plot(x_values, y_values_1, marker='o', linestyle='-', color='b', label='Salario Real')\n",
    "# ax1.set_xlabel('Años')\n",
    "# ax1.set_ylabel('Mediana del Salario REAL', color='b')\n",
    "\n",
    "# # Trazar datos en el segundo eje Y\n",
    "# ax2.plot(x_values, y_values_2, marker='s', linestyle='--', color='r', label='Salario Nominal')\n",
    "# ax2.set_ylabel('Salario Medio', color='r')\n",
    "\n",
    "# # Agregar leyendas para las líneas\n",
    "# ax1.legend(loc='upper left', bbox_to_anchor=(0.05, 0.95))\n",
    "# ax2.legend(loc='upper left', bbox_to_anchor=(0.05, 0.87))\n",
    "\n",
    "# # Título del gráfico\n",
    "# plt.title('Mediana del Salario y Salario Medio Real')\n",
    "\n",
    "# # Muestra el gráfico\n",
    "# plt.show()\n",
    "# #plt.savefig('grafico_Salario.jpg', format='jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar el Salario minimo y el porcentaje pagado del salario minimo por la EAM y de esa medida se puede establecer el potencial de ingresos que tiene el sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construcción de los hechos estilizados para el empleo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo de Excel\n",
    "import pandas as pd     \n",
    "import numpy as np \n",
    "import glob as glob\n",
    "\n",
    "csv_files_gD = glob.glob('Data_GEIH\\\\Desocupados\\\\*.[Cc][Ss][Vv]', recursive=True)\n",
    "Dog_D =[]\n",
    "\n",
    "for filename in csv_files_gD:\n",
    "    if \"Desocupados2008.csv\" in filename:\n",
    "        data_gD = pd.read_csv(filename, sep=\",\", encoding='latin-1', error_bad_lines=False)\n",
    "    if \"Desocupados2017.csv\" in filename:\n",
    "        data_gD = pd.read_csv(filename, sep=\",\", encoding='latin-1', error_bad_lines=False)\n",
    "    elif \"Desocupados2020.CSV\" in filename:\n",
    "        data_gD = pd.read_csv(filename, sep=\",\", encoding='latin-1', error_bad_lines=False)\n",
    "\n",
    "    else:\n",
    "        data_gD = pd.read_csv(filename,sep=\";\",encoding='latin-1', error_bad_lines=False)\n",
    "        \n",
    "    Dog_D.append(data_gD)\n",
    "\n",
    "GEIH_D08,GEIH_D09,GEIH_D10,GEIH_D11,GEIH_D12,GEIH_D13,GEIH_D14, \\\n",
    "    GEIH_D15,GEIH_D16,GEIH_D17,GEIH_D18,GEIH_D19,GEIH_D20 = Dog_D\n",
    "GEIH_LIST_D=[GEIH_D08,GEIH_D09,GEIH_D10,GEIH_D11,GEIH_D12,GEIH_D13,GEIH_D14, \\\n",
    "    GEIH_D15,GEIH_D16,GEIH_D17,GEIH_D18,GEIH_D19,GEIH_D20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_g = glob.glob('Data_GEIH\\\\Ocupados\\\\*.[Cc][Ss][Vv]', recursive=True)\n",
    "Dog =[]\n",
    "\n",
    "for filename in csv_files_g:\n",
    "    if \"Ocupados2008.csv\" in filename:\n",
    "        data_g = pd.read_csv(filename, sep=\",\", encoding='latin-1', error_bad_lines=False)   \n",
    "    elif \"Ocupados2011.csv\" in filename:\n",
    "        data_g = pd.read_csv(filename, sep=\",\", encoding='latin-1', error_bad_lines=False)    \n",
    "    elif \"Ocupados2017.csv\" in filename:\n",
    "        data_g = pd.read_csv(filename, sep=\",\", encoding='latin-1', error_bad_lines=False)\n",
    "    elif \"Ocupados2020.CSV\" in filename:\n",
    "        data_g = pd.read_csv(filename, sep=\",\", encoding='latin-1', error_bad_lines=False)\n",
    "    else:\n",
    "        data_g = pd.read_csv(filename,sep=\";\",encoding='latin-1', error_bad_lines=False)\n",
    "        \n",
    "    Dog.append(data_g)\n",
    "\n",
    "GEIH_O08,GEIH_O09,GEIH_O10,GEIH_O11,GEIH_O12,GEIH_O13,GEIH_O14,GEIH_O15,GEIH_O16,GEIH_O17,GEIH_O18,GEIH_O19,GEIH_O20 = Dog\n",
    "GEIH_LIST_O=[GEIH_O08,GEIH_O09,GEIH_O10,GEIH_O11,GEIH_O12,GEIH_O13,GEIH_O14,\n",
    "    GEIH_O15,GEIH_O16,GEIH_O17,GEIH_O18,GEIH_O19,GEIH_O20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEIH_LIST_D = change_label(GEIH_LIST_D)\n",
    "GEIH_LIST_O = change_label(GEIH_LIST_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEIH_LIST_D[12].columns.values[6]=\"RAMA4D_D\"\n",
    "GEIH_LIST_O[12].columns.values[6]=\"RAMA4D\"\n",
    "GEIH_LIST_O[12].columns.values[9]=\"FEX_C_2011\"\n",
    "GEIH_LIST_D[12].columns.values[9]=\"FEX_C_2011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEIH_LIST_O=Sort(\"RAMA4D\",GEIH_LIST_O)\n",
    "GEIH_LIST_D=Sort(\"RAMA4D_D\",GEIH_LIST_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEIH_G08,GEIH_G09,GEIH_G10,GEIH_G11,GEIH_G12,GEIH_G13,GEIH_G14,GEIH_G15,GEIH_G16,GEIH_G17,GEIH_G18,GEIH_G19,GEIH_G20 = 0,0,0,0,0,0,0,0,0,0,0,0,0 \n",
    "GEIH_G=[GEIH_G08,GEIH_G09,GEIH_G10,GEIH_G11,GEIH_G12,GEIH_G13,GEIH_G14,\n",
    "    GEIH_G15,GEIH_G16,GEIH_G17,GEIH_G18,GEIH_G19,GEIH_G20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEIH_GD08,GEIH_GD09,GEIH_GD10,GEIH_GD11,GEIH_GD12,GEIH_GD13,GEIH_GD14,GEIH_GD15,GEIH_GD16,GEIH_GD17,GEIH_GD18,GEIH_GD19,GEIH_GD20 = 0,0,0,0,0,0,0,0,0,0,0,0,0 \n",
    "GEIH_GD=[GEIH_GD08,GEIH_GD09,GEIH_GD10,GEIH_GD11,GEIH_GD12,GEIH_GD13,GEIH_GD14,\n",
    "    GEIH_GD15,GEIH_GD16,GEIH_GD17,GEIH_GD18,GEIH_GD19,GEIH_GD20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(GEIH_LIST_D)):\n",
    "    index=GEIH_LIST_D[i][\"RAMA4D_D\"].drop_duplicates().sort_values()\n",
    "    GEIH_GD[i]= pd.DataFrame(index=index,columns=[\"Number_Workers_D\",\"fact_c_D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(GEIH_LIST_O)):\n",
    "    index=GEIH_LIST_O[i][\"RAMA4D\"].drop_duplicates().sort_values()\n",
    "    GEIH_G[i]= pd.DataFrame(index=index,columns=[\"Number_Workers\",\"fact_c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in GEIH_LIST_O:\n",
    "    condition = j[\"P6870\"].apply(lambda x: x == 9)\n",
    "    if condition.any():\n",
    "        GEIH_G=calculate_avg_or_sum(\"RAMA4D\", \"RAMA4D\", \"Number_Workers\", GEIH_G, GEIH_LIST_O, \"count\")\n",
    "        GEIH_G=calculate_avg_or_sum(\"RAMA4D\", \"FEX_C_2011\", \"fact_c\", GEIH_G, GEIH_LIST_O, \"sum\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in GEIH_LIST_D:\n",
    "    condition = j[\"P7360\"].apply(lambda x: x == 9)\n",
    "    if condition.any():\n",
    "        GEIH_GD=calculate_avg_or_sum(\"RAMA4D_D\", \"RAMA4D_D\", \"Number_Workers_D\", GEIH_GD, GEIH_LIST_D, \"count\")\n",
    "        GEIH_GD=calculate_avg_or_sum(\"RAMA4D_D\", \"FEX_C_2011\", \"fact_c_D\", GEIH_GD, GEIH_LIST_D, \"sum\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df  in GEIH_GD:\n",
    "    df[\"Real_Rama_D\"] = df.apply(lambda row: mul_of_rows(row,\"Number_Workers_D\",\"fact_c_D\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df  in GEIH_G:\n",
    "    df[\"Real_Rama\"] = df.apply(lambda row: mul_of_rows(row,\"Number_Workers\",\"fact_c\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEIH08,GEIH09,GEIH10,GEIH11,GEIH12,GEIH13,GEIH14,GEIH15,GEIH16,GEIH17,GEIH18,GEIH19,GEIH20 = 0,0,0,0,0,0,0,0,0,0,0,0,0 \n",
    "GEIH=[GEIH08,GEIH09,GEIH10,GEIH11,GEIH12,GEIH13,GEIH14,\n",
    "    GEIH15,GEIH16,GEIH17,GEIH18,GEIH19,GEIH20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, geih_df in enumerate(GEIH_G):\n",
    "    data_df = Data_Gruop[i]  # Obtener el DataFrame correspondiente de Data_Gruop\n",
    "    \n",
    "    # Reindexar el DataFrame de GEIH_G para que tenga los mismos índices que el de Data_Gruop\n",
    "    geih_df = geih_df.reindex(index=data_df.index)\n",
    "    \n",
    "    # Si deseas eliminar las filas que no coinciden en índices, puedes hacerlo así\n",
    "    geih_df.dropna(inplace=True)\n",
    "    \n",
    "    # Ahora, geih_df contiene solo las filas que coinciden en índices con data_df\n",
    "    \n",
    "    # Si deseas guardar el DataFrame actualizado de GEIH_G de nuevo en la lista, puedes hacerlo así\n",
    "    GEIH_G[i] = geih_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, geih_df in enumerate(GEIH_GD):\n",
    "    data_df = Data_Gruop[i]  # Obtener el DataFrame correspondiente de Data_Gruop\n",
    "    \n",
    "    # Reindexar el DataFrame de GEIH_G para que tenga los mismos índices que el de Data_Gruop\n",
    "    geih_df = geih_df.reindex(index=data_df.index)\n",
    "    \n",
    "    # Si deseas eliminar las filas que no coinciden en índices, puedes hacerlo así\n",
    "    geih_df.dropna(inplace=True)\n",
    "    \n",
    "    # Ahora, geih_df contiene solo las filas que coinciden en índices con data_df\n",
    "    \n",
    "    # Si deseas guardar el DataFrame actualizado de GEIH_G de nuevo en la lista, puedes hacerlo así\n",
    "    GEIH_GD[i] = geih_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, geih_df in enumerate(GEIH_G):\n",
    "    data_df = GEIH_GD[i]  # Obtener el DataFrame correspondiente de Data_Gruop\n",
    "    \n",
    "    # Reindexar el DataFrame de GEIH_G para que tenga los mismos índices que el de Data_Gruop\n",
    "    geih_df = geih_df.reindex(index=data_df.index)\n",
    "    \n",
    "    # Si deseas eliminar las filas que no coinciden en índices, puedes hacerlo así\n",
    "    geih_df.dropna(inplace=True)\n",
    "    \n",
    "    # Ahora, geih_df contiene solo las filas que coinciden en índices con data_df\n",
    "    \n",
    "    # Si deseas guardar el DataFrame actualizado de GEIH_G de nuevo en la lista, puedes hacerlo así\n",
    "    GEIH[i] = geih_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuc = create_index(Data_Gruop)\n",
    "X=['Ocupados']\n",
    "Empleo = pd.DataFrame(index=Index, columns=X)\n",
    "Empleo['Desocupados'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=[]\n",
    "Y=[]\n",
    "for i in GEIH_G:\n",
    "    X = i['Real_Rama'].sum()\n",
    "    T.append(X)\n",
    "\n",
    "for i in GEIH_GD:\n",
    "    W = i['Real_Rama_D'].sum()\n",
    "    Y.append(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Empleo['Ocupados'] = T\n",
    "Empleo['Desocupados'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supongamos que 'df' es tu DataFrame con un índice y valores que deseas graficar\n",
    "# Asegúrate de que 'df' esté cargado correctamente con tus datos.\n",
    "\n",
    "# Crear la gráfica\n",
    "# Tamaño de la gráfica (ajusta según tus preferencias)\n",
    "plt.plot(df.index, Empleo['Ocupados'], marker='o', linestyle='-', color='b', label='Datos')  # Trazar los datos\n",
    "\n",
    "# Personalizar la gráfica\n",
    "plt.xlabel('Año')  # Etiqueta del eje X (ajusta el texto según tus preferencias)\n",
    "plt.ylabel('Valores')  # Etiqueta del eje Y (ajusta el texto según tus preferencias)\n",
    "plt.title('Ocupados')  # Título de la gráfica (ajusta el texto según tus preferencias)\n",
    "plt.grid(True)  # Mostrar una cuadrícula en el gráfico si es necesario\n",
    "plt.legend()  # Mostrar leyenda si es necesario\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
